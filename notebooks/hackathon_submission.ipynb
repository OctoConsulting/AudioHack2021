{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1df4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import warnings                               # Suppressing annoying Librosa warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from os import walk\n",
    "import shutil                                 # For shell commands, accessing and manipulating files and directories\n",
    "\n",
    "from icecream import ic\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd                           # Data analysis\n",
    "from collections import Counter\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import metrics as sk\n",
    "\n",
    "import librosa                                # Manipulating sound files\n",
    "from librosa import display\n",
    "import IPython.display as ipd\n",
    "import soundfile\n",
    "import glob \n",
    "\n",
    "\n",
    "import tensorflow as tf                       # Deep Learning\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LambdaCallback, TensorBoard\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt               # Visualizations\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import normalize   # Data Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f26d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path might require modification\n",
    "\n",
    "model_a = tf.keras.models.load_model('saved_model/model_angle_2.h5')\n",
    "model_d = tf.keras.models.load_model('saved_model/model_distance_2.h5')\n",
    "a_dict = {0: 0,\n",
    "              20: 1,\n",
    "              40: 2,\n",
    "              60: 3,\n",
    "              80: 4,\n",
    "              100: 5,\n",
    "              120: 6,\n",
    "              140: 7,\n",
    "              160: 8,\n",
    "              180: 9,\n",
    "              200: 10,\n",
    "              220: 11,\n",
    "              240: 12,\n",
    "              260: 13,\n",
    "              280: 14,\n",
    "              300: 15,\n",
    "              320: 16,\n",
    "              340: 17}\n",
    "d_dict = {10: 0,\n",
    "              20: 1,\n",
    "              30: 2,\n",
    "              40: 3,\n",
    "              50: 4,\n",
    "              60: 5,\n",
    "              70: 6,\n",
    "              80: 7,\n",
    "              90: 8,\n",
    "              100: 9,\n",
    "              110: 10,\n",
    "              120: 11,\n",
    "              130: 12,\n",
    "              140: 13,\n",
    "              150: 14,\n",
    "              160: 15,\n",
    "              170: 16,\n",
    "              180: 17,\n",
    "              190: 18,\n",
    "              200: 19,\n",
    "              210: 20,\n",
    "              220: 21,\n",
    "              230: 22,\n",
    "              240: 23,\n",
    "              250: 24,\n",
    "              260: 25,\n",
    "              270: 26,\n",
    "              280: 27,\n",
    "              290: 28,\n",
    "              300: 29}\n",
    "a_dict=  {val:key for key, val in a_dict.items()}\n",
    "d_dict=  {val:key for key, val in d_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c84ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_inference(a_inference, d_inference, window=False):\n",
    "    # Path might require modification\n",
    "    path = './compass.png'\n",
    "\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((300,300), Image.ANTIALIAS)\n",
    "    img = cv2.cvtColor(numpy.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    start_point = (150, 150) \n",
    "\n",
    "    length = 71\n",
    "    angle = np.radians(a_inference)\n",
    "    dist = d_inference\n",
    "\n",
    "    end_point = (int(150 + length * np.sin(angle)), int(150 - length * np.cos(angle)))\n",
    " \n",
    "    color = (255, 0, 0) \n",
    "\n",
    "    thickness = 5\n",
    "\n",
    "\n",
    "    img = cv2.arrowedLine(np.asarray(img), start_point, end_point,\n",
    "                                         color, thickness) \n",
    "    # text\n",
    "    text = f'{dist} m to {a_inference} degrees'\n",
    "\n",
    "    # font\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # org\n",
    "    org = (35, 290)\n",
    "\n",
    "    # fontScale\n",
    "    fontScale = 0.75\n",
    "\n",
    "    # Red color in BGR\n",
    "    color = (255, 0, 0)\n",
    "\n",
    "    # Line thickness of 2 px\n",
    "    thickness = 2\n",
    "\n",
    "    # Using cv2.putText() method\n",
    "    image = cv2.putText(np.asarray(img), text, org, font, fontScale, \n",
    "                     color, thickness, cv2.LINE_AA, False)\n",
    "\n",
    "    if window:\n",
    "        img = ImageTk.PhotoImage(Image.fromarray(img), master=window)\n",
    "    else:\n",
    "        img = ImageTk.PhotoImage(Image.fromarray(img))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Join\")\n",
    "window.geometry(\"300x300\")\n",
    "window.configure(background='grey')\n",
    "\n",
    "img = Image.open('./compass.png')\n",
    "img = img.resize((300,300), Image.ANTIALIAS)\n",
    "img = cv2.cvtColor(numpy.array(img), cv2.COLOR_RGB2BGR)\n",
    "img = ImageTk.PhotoImage(Image.fromarray(img))\n",
    "\n",
    "panel = tk.Label(window, image = img)\n",
    "\n",
    "#The Pack geometry manager packs widgets in rows or columns.\n",
    "panel.pack(side = \"bottom\", fill = \"both\", expand = \"yes\")\n",
    "\n",
    "#Start the GUI\n",
    "\n",
    "window.lift()\n",
    "window.attributes('-topmost',True)\n",
    "#window.after_idle(root.attributes,'-topmost',False)\n",
    "\n",
    "# This path must be set to point to the unity app audio output directory, which should be similar to this\n",
    "path = 'C:\\\\Users\\\\Aaron.Festinger\\\\AppData\\\\LocalLow\\\\Seeing Ear Bats\\\\Hack-a-thon_2021\\\\'\n",
    "#print('Your folder path is \"',path,'\"')\n",
    "before = dict ([(f, None) for f in os.listdir (path)])\n",
    "\n",
    "def dothis():\n",
    "    global before\n",
    "    after = dict ([(f, None) for f in os.listdir (path)])\n",
    "    added = [f for f in after if not f in before]\n",
    "    if added:\n",
    "            #print(\"Added: \", \", \".join (added))\n",
    "            sample, _ = librosa.load(path+added[-1])\n",
    "            sample = np.array(sample[1000:16000])\n",
    "            sample = np.reshape(sample, (1, sample.shape[0], 1))\n",
    "\n",
    "            before = dict ([(f, None) for f in os.listdir (path)])\n",
    "            change_image(sample)\n",
    "    window.after(1000,dothis)\n",
    "\n",
    "def change_image(obs):\n",
    "    global window\n",
    "    img = visualize_inference(a_dict[np.argmax(model_a.predict(obs))], d_dict[np.argmax(model_d.predict(obs))], window=window)\n",
    "    panel.configure(image=img)\n",
    "    panel.image = img\n",
    "\n",
    "    \n",
    "    \n",
    "window.after(500, dothis)\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b2102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAAIenv",
   "language": "python",
   "name": "saaienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
